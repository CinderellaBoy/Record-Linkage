{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf6329b5",
   "metadata": {},
   "source": [
    "## 第 1 步：导入依赖与工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58979604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 依赖库导入 ---------- #\n",
    "import re, time\n",
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "from joblib import Parallel, delayed\n",
    "from rapidfuzz import fuzz, distance\n",
    "import jellyfish\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa7d606",
   "metadata": {},
   "source": [
    "## 第 2 步：标准化函数 & 阻塞函数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "363aeb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 数据标准化 ---------- #\n",
    "def read_df(path):\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def normalize(txt: str) -> str:\n",
    "    txt = unidecode(txt or \"\").lower()\n",
    "    txt = re.sub(r\"[^a-z0-9\\s]\", \" \", txt)\n",
    "    return \" \".join(txt.split())\n",
    "\n",
    "def standardize(df, col):\n",
    "    tqdm.pandas(desc=f\"Normalize {col}\")\n",
    "    df[\"norm\"] = df[col].progress_apply(normalize)\n",
    "    return df\n",
    "\n",
    "# ---------- 阻塞方法 ---------- #\n",
    "def minhash_2g(s):\n",
    "    m = MinHash(num_perm=128)\n",
    "    for g in [s[i:i+2] for i in range(len(s)-1)] or [s]:\n",
    "        m.update(g.encode())\n",
    "    return m\n",
    "\n",
    "def block_key_B(s): return f\"{s[0]}_{len(s)//4}\"\n",
    "def block_key_C(s): return f\"{jellyfish.soundex(s)}_{s[:3]}\"\n",
    "\n",
    "def add_blocks(df):\n",
    "    tqdm.pandas(desc=\"Blocking keys\")\n",
    "    df[\"mh\"]   = df[\"norm\"].progress_apply(minhash_2g)\n",
    "    df[\"keyB\"] = df[\"norm\"].apply(block_key_B)\n",
    "    df[\"keyC\"] = df[\"norm\"].apply(block_key_C)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第 3 步：构建候选对生成逻辑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca08df84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 候选对生成 ---------- #\n",
    "def lsh_build(df, tag, thr=0.65):\n",
    "    lsh = MinHashLSH(threshold=thr, num_perm=128)\n",
    "    for i, row in df.iterrows():\n",
    "        lsh.insert(f\"{tag}_{i}\", row.mh)\n",
    "    return lsh\n",
    "\n",
    "def pairs_from_lsh(query, ref, lsh, tag):\n",
    "    out = []\n",
    "    for qi, q in tqdm(query.iterrows(), total=len(query), desc=f\"L‑query {tag}\"):\n",
    "        for k in lsh.query(q.mh):\n",
    "            ri = int(k.split('_')[1])\n",
    "            out.append((qi, ri))\n",
    "    return out\n",
    "\n",
    "def pairs_from_key(query, ref, col, tag):\n",
    "    grp = ref.groupby(col)\n",
    "    out = []\n",
    "    for qi, q in tqdm(query.iterrows(), total=len(query), desc=f\"Key‑query {tag}:{col}\"):\n",
    "        if q[col] in grp.groups:\n",
    "            out.extend([(qi, ri) for ri in grp.get_group(q[col]).index])\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c904fad7",
   "metadata": {},
   "source": [
    "## 第 4 步：特征构建 & Top-N 策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d370ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 特征构建函数 ---------- #\n",
    "def build_feature_row(q, r):\n",
    "    a, b = q.norm, r.norm\n",
    "    tokA, tokB = set(a.split()), set(b.split())\n",
    "    feat = dict(\n",
    "        jw          = fuzz.WRatio(a, b) / 100,\n",
    "        lev_ratio   = 1 - distance.Levenshtein.normalized_distance(a, b),\n",
    "        token_set   = fuzz.token_set_ratio(a, b) / 100,\n",
    "        short_prefix= int(a[:4] == b[:4] and abs(len(a)-len(b)) <= 3),\n",
    "        soundex_eq  = int(jellyfish.soundex(a) == jellyfish.soundex(b)),\n",
    "        jaccard     = len(tokA & tokB) / len(tokA | tokB or {\"\"})\n",
    "    )\n",
    "    feat.update(id_left=q.ID, id_right=r.ID)\n",
    "    return feat\n",
    "\n",
    "def generate_pairs(query, ref, tag, top_n=100):\n",
    "    lsh = lsh_build(ref, f\"{tag}A\")\n",
    "    idx = set(pairs_from_lsh(query, ref, lsh, f\"{tag}A\") +\n",
    "              pairs_from_key(query, ref, \"keyB\", f\"{tag}B\") +\n",
    "              pairs_from_key(query, ref, \"keyC\", f\"{tag}C\"))\n",
    "    \n",
    "    grouped = {}\n",
    "    for i, j in idx:\n",
    "        grouped.setdefault(i, []).append(j)\n",
    "\n",
    "    reduced_pairs = []\n",
    "    for i, js in grouped.items():\n",
    "        js_sorted = sorted(js, key=lambda j: fuzz.WRatio(query.loc[i].norm, ref.loc[j].norm), reverse=True)\n",
    "        for j in js_sorted[:top_n]:\n",
    "            reduced_pairs.append((i, j))\n",
    "\n",
    "    feats = Parallel(n_jobs=-1)(\n",
    "        delayed(build_feature_row)(query.loc[i], ref.loc[j])\n",
    "        for i, j in tqdm(reduced_pairs, desc=f\"Building {tag}\")\n",
    "    )\n",
    "    return pd.DataFrame(feats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第 5 步：数据标注与采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bfb8f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 标注与采样 ---------- #\n",
    "def label(df):\n",
    "    df[\"Y\"] = (df.id_left == df.id_right).astype(int)\n",
    "    return df\n",
    "\n",
    "def downsample(df, r=4):\n",
    "    pos = df[df.Y == 1]\n",
    "    neg = df[df.Y == 0].sample(min(len(df[df.Y == 0]), r * len(pos)), random_state=42)\n",
    "    return pd.concat([pos, neg]).sample(frac=1, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0016979f",
   "metadata": {},
   "source": [
    "## 第 6 步：加载数据 + 特征提取 + 保存中间文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9796a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Normalize NAME: 100%|██████████| 16041/16041 [00:00<00:00, 426300.21it/s]\n",
      "Blocking keys: 100%|██████████| 16041/16041 [00:18<00:00, 866.40it/s]\n",
      "Normalize NAME: 100%|██████████| 19525/19525 [00:00<00:00, 318656.58it/s]\n",
      "Blocking keys: 100%|██████████| 19525/19525 [00:22<00:00, 863.96it/s]\n",
      "Normalize VARIANT: 100%|██████████| 16041/16041 [00:00<00:00, 342141.87it/s]\n",
      "Blocking keys: 100%|██████████| 16041/16041 [00:20<00:00, 778.60it/s]\n",
      "L‑query P-PA: 100%|██████████| 16041/16041 [00:01<00:00, 11219.08it/s]\n",
      "Key‑query P-PB:keyB: 100%|██████████| 16041/16041 [00:03<00:00, 4368.53it/s]\n",
      "Key‑query P-PC:keyC: 100%|██████████| 16041/16041 [00:03<00:00, 4195.41it/s]\n",
      "Building P-P: 100%|██████████| 1227137/1227137 [09:23<00:00, 2176.06it/s]\n",
      "L‑query A-AA: 100%|██████████| 19525/19525 [00:01<00:00, 12105.68it/s]\n",
      "Key‑query A-AB:keyB: 100%|██████████| 19525/19525 [00:04<00:00, 4070.39it/s]\n",
      "Key‑query A-AC:keyC: 100%|██████████| 19525/19525 [00:03<00:00, 5913.22it/s]\n",
      "Building A-A: 100%|██████████| 1560830/1560830 [12:13<00:00, 2127.13it/s]\n",
      "L‑query A-PA: 100%|██████████| 19525/19525 [00:01<00:00, 12146.16it/s]\n",
      "Key‑query A-PB:keyB: 100%|██████████| 19525/19525 [00:04<00:00, 4458.90it/s]\n",
      "Key‑query A-PC:keyC: 100%|██████████| 19525/19525 [00:02<00:00, 7363.14it/s]\n",
      "Building A-P: 100%|██████████| 1440188/1440188 [10:45<00:00, 2231.51it/s]\n",
      "L‑query T-PAA: 100%|██████████| 16041/16041 [00:01<00:00, 11704.93it/s]\n",
      "Key‑query T-PAB:keyB: 100%|██████████| 16041/16041 [00:05<00:00, 3137.65it/s]\n",
      "Key‑query T-PAC:keyC: 100%|██████████| 16041/16041 [00:02<00:00, 6617.65it/s]\n",
      "Building T-PA: 100%|██████████| 1411220/1411220 [11:04<00:00, 2124.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# ---------- 加载并保存候选对 ---------- #\n",
    "P = add_blocks(standardize(read_df(\"primary.csv\"), \"NAME\"))\n",
    "A = add_blocks(standardize(read_df(\"alternate.csv\"), \"NAME\"))\n",
    "T = add_blocks(standardize(read_df(\"test_01.csv\"), \"VARIANT\"))\n",
    "\n",
    "pairs_dedup = pd.concat([\n",
    "    label(generate_pairs(P, P, \"P-P\")),\n",
    "    label(generate_pairs(A, A, \"A-A\")),\n",
    "    label(generate_pairs(A, P, \"A-P\"))\n",
    "]).drop_duplicates()\n",
    "pairs_map = label(generate_pairs(T, pd.concat([P, A]).reset_index(drop=True), \"T-PA\"))\n",
    "\n",
    "# 保存中间文件，便于重复调参无需重跑前几步\n",
    "pairs_dedup.to_csv(\"pairs_dedup.csv\", index=False)\n",
    "pairs_map.to_csv(\"pairs_map.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967f97f5",
   "metadata": {},
   "source": [
    "## 第 7 步：加载缓存文件 + 拟合模型（XGBoost）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc8e00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.80 → Precision 0.487 Recall 0.816 F1 0.610\n",
      "Threshold 0.85 → Precision 0.637 Recall 0.774 F1 0.699\n",
      "Threshold 0.89 → Precision 0.825 Recall 0.722 F1 0.770\n",
      "Threshold 0.90 → Precision 0.864 Recall 0.712 F1 0.780\n",
      "Threshold 0.91 → Precision 0.892 Recall 0.699 F1 0.784\n",
      "Threshold 0.92 → Precision 0.924 Recall 0.680 F1 0.783\n",
      "Threshold 0.95 → Precision 0.950 Recall 0.606 F1 0.740\n"
     ]
    }
   ],
   "source": [
    "# ---------- 加载训练数据 ---------- #\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "pairs_dedup = pd.read_csv(\"pairs_dedup.csv\")\n",
    "pairs_map   = pd.read_csv(\"pairs_map.csv\")\n",
    "\n",
    "def downsample(df, r=4):\n",
    "    pos = df[df.Y == 1]\n",
    "    neg = df[df.Y == 0].sample(min(len(df[df.Y == 0]), r * len(pos)), random_state=42)\n",
    "    return pd.concat([pos, neg]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "train_df = downsample(pairs_dedup, r=4)\n",
    "X, y = train_df.drop(columns=[\"id_left\", \"id_right\", \"Y\"]), train_df.Y\n",
    "val_cut = int(0.2 * len(X))\n",
    "Xv, yv = X.iloc[:val_cut], y.iloc[:val_cut]\n",
    "Xt, yt = X.iloc[val_cut:], y.iloc[val_cut:]\n",
    "\n",
    "# ---------- 模型训练 (Random Forest) ---------- #\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=5,        \n",
    "    class_weight='balanced_subsample',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ").fit(Xt, yt)\n",
    "\n",
    "# ---------- 模型预测 & 阈值评估 ---------- #\n",
    "Xm, ym = pairs_map.drop(columns=[\"id_left\", \"id_right\", \"Y\"]), pairs_map.Y\n",
    "prob = clf.predict_proba(Xm)[:, 1]\n",
    "\n",
    "# 多阈值尝试\n",
    "for t in [0.8, 0.85, 0.89, 0.9, 0.91, 0.92, 0.95]:\n",
    "    ypred = (prob >= t).astype(int)\n",
    "    p, r, f, _ = precision_recall_fscore_support(ym, ypred, average='binary', zero_division=0)\n",
    "    print(f\"Threshold {t:.2f} → Precision {p:.3f} Recall {r:.3f} F1 {f:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12c354e",
   "metadata": {},
   "source": [
    "## 第 8 步：测试评估指标输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59edebcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Mapping Metrics ===\n",
      "Precision 0.910 Recall 0.697 F1 0.790\n",
      "Accuracy 0.995 ROC-AUC 0.990 PR-AUC 0.815\n"
     ]
    }
   ],
   "source": [
    "# ---------- 评估预测 ---------- #\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_fscore_support,\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    average_precision_score\n",
    ")\n",
    "\n",
    "thr = 0.91\n",
    "Xm, ym = pairs_map.drop(columns=[\"id_left\", \"id_right\", \"Y\"]), pairs_map.Y\n",
    "prob = clf.predict_proba(Xm)[:, 1]\n",
    "ypred = (prob >= thr).astype(int)\n",
    "\n",
    "p, r, f, _ = precision_recall_fscore_support(ym, ypred, average='binary')\n",
    "acc = accuracy_score(ym, ypred)\n",
    "auc = roc_auc_score(ym, prob)\n",
    "pr_auc = average_precision_score(ym, prob)\n",
    "\n",
    "print(\"\\n=== Final Mapping Metrics ===\")\n",
    "print(f\"Precision {p:.3f} Recall {r:.3f} F1 {f:.3f}\")\n",
    "print(f\"Accuracy {acc:.3f} ROC-AUC {auc:.3f} PR-AUC {pr_auc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2602d8",
   "metadata": {},
   "source": [
    "## 第 9 步：Top-1 Accuracy 输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afeb86c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top‑1 Accuracy: 84.055%\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.999     0.997   1390884\n",
      "           1      0.910     0.697     0.790     20336\n",
      "\n",
      "    accuracy                          0.995   1411220\n",
      "   macro avg      0.953     0.848     0.893   1411220\n",
      "weighted avg      0.994     0.995     0.994   1411220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------- Top‑1 精度输出 ---------- #\n",
    "pairs_map[\"prob\"] = prob\n",
    "\n",
    "# 获取每个测试样本（以 id_right 为单位）预测概率最高的候选对\n",
    "top1 = pairs_map.sort_values(\"prob\", ascending=False).groupby(\"id_right\").head(1)\n",
    "\n",
    "# Top‑1 Accuracy：每个测试样本的第一候选是否预测为 Y=1（即匹配成功）\n",
    "top1_acc = top1.eval(\"Y == 1\").mean()\n",
    "print(f\"\\nTop‑1 Accuracy: {top1_acc:.3%}\")\n",
    "\n",
    "# 输出运行时间（确保 start 已定义）\n",
    "# print(f\"Total runtime: {time.time() - start:.1f} s\")\n",
    "\n",
    "# 输出分类报告（Precision, Recall, F1 按类别划分）\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(classification_report(ym, ypred, digits=3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SAMbase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
